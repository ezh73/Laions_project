## Laions — 팬 참여형 AI 야구 예측 플랫폼

> "AI와 함께 즐기는 야구 — 팬들의 예측과 경쟁의 장"

-----

### 1\. 프로젝트 개요 (Overview)

기존 야구 포털은 경기 정보나 뉴스 등 일방적인 정보 제공에 그쳐 팬들의 참여가 제한적  
Laions는 이러한 문제를 해결하기 위해, AI를 단순한 예측 도구가 아닌 \*\*"함께 즐기는 경쟁 상대"\*\*로 제시하여   
팬들이 직접 예측하고, 배우고, 경쟁하는 새로운 경험을 제공하는 것을 목표로 함

-----

### 2\. 핵심 기능 (Features)

  * **AI 승리예측 대결:** LightGBM 기반의 AI 모델의 정규시즌의 경기결과 예측과 대결, AI를 이기면 가산점 부여
  * **AI 퀴즈:** Gemini API로 생성된 퀴즈를 풀며 재미와 학습을 동시에 얻는 참여형 콘텐츠
  * **주간 팬 랭킹:** 예측과 퀴즈 점수를 합산하여 팬들 간의 순위를 보여주는 게임화(Gamification) 요소
  * **정규시즌/포스트시즌/비시즌 모드:** 시즌 진행도에 따라 정규시즌 경기 예측, 포스트시즌 삼성라이온즈의 다음 시리즈 진출 확률 예측, 비시즌엔 이번시즌 성적을 기반으로 Monte Carlo 기법을 사용하여 다음시즌 순위 예측

-----

### 3\. 아키텍처 및 기술 스택 (Architecture & Tech Stack)

| 구분 | 기술 | 선택 이유 |
| :--- | :--- | :--- |
| **Frontend** | React + MUI | 컴포넌트 기반 구조로 유지보수 용이, 빠른 UI 구현 |
| **Backend** | FastAPI | Python AI 생태계와 자연스럽게 연결, 비동기 처리에 우수 |
| **Database** | PostgreSQL | 정형 데이터 관리에 안정적이며, Python과 호환성이 높음 |
| **AI Model** | LightGBM | ELO, 폼 등 수치형 피처 처리에 최적화되고 학습 속도가 빠름 |
| **Scheduler**| GitHub Actions | 서버 종료 시에도 매일 데이터 수집 및 예측 자동화 가능 |

-----

### 4\. 주요 기술적 도전 및 해결 과정 (Key Challenges & Solutions)

#### 1\. 불안정한 웹 스크래핑 문제 해결

  * **문제:** 초기 데이터 수집 시, 동적으로 로딩되는 콘텐츠 때문에 BeautifulSoup으로는 한계를 느낌
  * **해결:** 개발자 도구의 네트워크 탭을 분석하여 페이지가 사용하는 **내부 API 엔드포인트를 직접 찾아냄.** 이를 통해 HTML 파싱보다 훨씬 안정적으로 원본 JSON 데이터를 확보하는 데 성공함.

#### 2\. AI 예측 모델의 전략적 선택

  * **문제:** KBO의 모든 상세 스탯을 경기 날짜별로 수집하기 어렵다는 현실적인 제약
  * **해결:** 복잡한 스탯 대신, 경기 승패 결과만으로 팀의 실력을 가장 효율적으로 압축하는 **Elo Rating을 핵심 피처로 선택.** 이는 FiveThirtyEight과 같은 해외 유명 매체에서도 사용하는 검증된 방식. 최종적으로 여러 모델을 비교 테스트한 결과, **가장 높은 성능(61.97%)을 보인 LightGBM**을 채택.

#### 3\. 테스트 용이성 확보를 위한 '관리자 모드' 설계

* **문제:** 시즌의 흐름(정규/포스트/비시즌)에 따라 기능이 달라져, 특정 시점이 아니면 테스트 자체가 불가능한 구조.
* **해결:** 실제 날짜와 시스템의 상태를 분리하는 **'관리자 모드'를 직접 설계**. 특히, 포스트시즌 테스트 시 외부 사이트 크롤링의 불안정성을 피하기 위해, DB에 누적된 경기 기록을 바탕으로 **'ELO 기반 랭킹'을 동적으로 생성하여 최종 순위의 대리 지표(Proxy)로 활용**. 외부 의존성 없이 언제든지 모든 시즌의 기능을 안정적으로 테스트할 수 있는 환경을 구축.

  
#### 4\. 실시간 퀴즈 생성 대신 DB 캐싱 사용

  * **문제:** 실시간으로 퀴즈를 생성할 경우 생성 속도가 느려 사용자의 불편을 초래.
  * **해결:** 퀴즈를 미리 만들어 DB에 저장한 다음 그것을 불러오는 캐싱을 사용하여 속도를 높임.

-----

### 5. 설치 및 실행 (Setup)

본 프로젝트를 로컬 환경에서 실행하기 위해서는 프론트엔드와 백엔드를 각각 설정하고 실행해야 함.

---

#### **1️⃣ Backend Server (첫 번째 터미널)**

1.  **프로젝트 클론 및 이동**
    ```bash
    git clone https://github.com/ezh73/Laions_project.git   
    cd Laions_project/backend
    ```

2.  **가상환경 생성 및 활성화**
    ```bash
    python -m venv venv

    # Windows PowerShell
    venv\Scripts\activate

    # macOS / Linux
    # source venv/bin/activate
    ```

3.  **의존성 패키지 설치**
    ```bash
    pip install -r requirements.txt
    ```

4.  **(중요) 환경 변수 및 인증 키 설정**
    프로젝트를 실행하려면 API 키와 데이터베이스 정보가 필요. `backend` 폴더 안에 아래의 두 파일을 직접 생성.

    **가. `.env` 파일 생성**
    `backend` 폴더에 `.env` 파일을 만들고, 아래 내용을 복사하여 자신의 키 값으로 채우기.
    ```ini
    # --- PostgreSQL 데이터베이스 연결 정보 ---
    DATABASE_URL="postgresql://user:password@localhost:5432/laions_db"

    # --- Google Gemini API 키 ---
    GEMINI_API_KEY="YOUR_GEMINI_API_KEY"

    # --- 관리자 API 인증을 위한 비밀 키 ---
    ADMIN_API_KEY="YOUR_SECRET_ADMIN_KEY"

    # --- (선택) 관리자 모드 시뮬레이션 설정 ---
    ADMIN_MODE=true
    ADMIN_DATE=2025-10-29
    ADMIN_OVERRIDE_MODE=postseason
    ```

    **나. `firebase-credentials.json` 파일 생성**
    Firebase 프로젝트에서 서비스 계정 비공개 키를 다운로드한 후, 파일명을 `firebase-credentials.json`으로 변경하여 `backend` 폴더에 위치.

5.  **백엔드 서버 실행**
    ```bash
    uvicorn main:app --reload
    ```
    > 백엔드 서버가 `http://localhost:8000` 에서 실행.

---

#### **2️⃣ Frontend Server (두 번째 터미널)**

1.  **프론트엔드 폴더로 이동 및 의존성 설치**
    ```bash
    cd ../laions-frontend  
    npm install
    ```

2.  **프론트엔드 서버 실행**
    ```bash
    npm start
    ```
    > 웹 브라우저에서 `http://localhost:3000` 으로 접속하여 서비스를 확인.

-----

### 6. 향후 개선 방향 (Future Improvements)

1.  **더 빠른 응답 속도를 위한 캐시 시스템 고도화**
    * **현재:** 퀴즈 기능의 속도를 높이기 위해 PostgreSQL 데이터베이스를 캐시처럼 사용.
    * **미래:** 사용자가 폭발적으로 늘어날 경우를 대비해, 데이터베이스의 부하를 줄이고 응답 속도를 극적으로 높일 수 있는 **Redis와 같은 전문 인메모리(In-Memory) 캐시 시스템을 도입**하여 더 쾌적한 사용자 경험을 제공할 수 있음.

2.  **AI 퀴즈의 신뢰도 향상**
    * **현재:** Gemini API가 자체 지식으로 퀴즈를 생성하기 때문에, 가끔 사실과 다른 내용을 만들어내는 '환각(Hallucination)' 현상의 위험 존재.
    * **미래:** 이 문제를 해결하기 위해, 검증된 KBO 공식 기록이나 뉴스 기사 데이터를 미리 준비해두고, AI가 **오직 이 '믿을 수 있는 자료' 안에서만** 퀴즈를 생성하도록 하는 **RAG(검색 증강 생성)** 기술을 적용하여 퀴즈의 신뢰도를 높임.

3.  **모델 자동 업데이트 파이프라인 구축 (MLOps)**
    * **현재:** 매일 새로운 경기 데이터를 수집하는 파이프라인은 자동화되어 있지만, 모델을 더 똑똑하게 만드는 '재학습' 과정은 수동으로 해야함.
    * **미래:** 여기서 한 단계 더 나아가, **"데이터 수집 → 모델 재학습 → 성능 검증 → 서비스 배포"** 에 이르는 전 과정을 자동화하는 **MLOps(머신러닝 운영) 파이프라인**을 구축. 이를 통해 항상 최신 데이터를 반영한 최고 성능의 모델을 안정적으로 서비스할 수 있음.
